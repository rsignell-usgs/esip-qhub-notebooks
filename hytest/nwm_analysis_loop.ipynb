{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23cabac-5a21-48d0-b7b1-e36671f0a718",
   "metadata": {},
   "source": [
    "# HyTest Hydrologic Model Assessment\n",
    "* get observed and modeled data via Intake catalog\n",
    "* use Dask to compute metrics in parallel\n",
    "* Use community tools (Pandas & Xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7e186-83be-4dae-87d8-d469beb4a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import intake\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62327185-50a2-4fa6-bdd1-5a876c918001",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A selection of traditional statistical metrics for comparing against d-score components\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def nse(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate the Nash-Sutcliffe Efficiency (NSE)\n",
    "    (https://www.sciencedirect.com/science/article/pii/0022169470902556?via%3Dihub)\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        Nash-Sutcliffe Efficiency\n",
    "    \"\"\"\n",
    "    return 1 - (mse(obs, mod) / np.var(obs))\n",
    "\n",
    "\n",
    "def mse(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate the mean squared error (MSE)\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        mean squared error\n",
    "    \"\"\"\n",
    "    return np.mean((obs - mod) ** 2)\n",
    "\n",
    "\n",
    "def pbias(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate the percent bias\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        Percent bias\n",
    "    \"\"\"\n",
    "    return 100 * ((np.sum(mod - obs)) / (np.sum(obs)))\n",
    "\n",
    "\n",
    "def pbias_percentile(obs, model, percentile, fun):\n",
    "    \"\"\"\n",
    "    Calculate the percent bias for a percentile bin\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "        percentile: float\n",
    "        fun: comparison function (e.g., np.greater)\n",
    "    Returns:\n",
    "        Percent bias for bin\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(obs, q=percentile)\n",
    "    i = fun(obs, threshold)\n",
    "    \n",
    "    return pbias(obs[i], model[i])\n",
    "    \n",
    "\n",
    "\n",
    "def pearson_r(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate Pearson's r\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        Pearson's r\n",
    "    \"\"\"\n",
    "    #return np.cov(mod, obs) / np.sqrt( np.var(mod) * np.var(obs))\n",
    "    return np.corrcoef(mod, obs)[0,1]\n",
    "\n",
    "\n",
    "def spearman_r(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate Spearman's r\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        Spearman's r\n",
    "    \"\"\"\n",
    "    return pearson_r(np.argsort(mod), np.argsort(obs))\n",
    "\n",
    "\n",
    "def kge(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate the Kling-Gupta Efficiency (KGE)\n",
    "    (https://www.sciencedirect.com/science/article/pii/S0022169409004843)\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        Kling-Gupta Efficiency\n",
    "    \"\"\"\n",
    "    #d_obs = obs - np.mean(obs)\n",
    "    #d_mod = mod - np.mean(mod)\n",
    "    #r = np.sum(d_obs * d_mod) / np.sqrt(np.sum(d_mod ** 2) * np.sum(d_obs ** 2))\n",
    "    r = pearson_r(obs, mod)\n",
    "    #alpha = np.std(mod) / np.std(obs)\n",
    "    alpha = sd_ratio(obs, mod)\n",
    "    beta = np.sum(mod) / np.sum(obs)\n",
    "\n",
    "    ED = np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "    return 1 - ED\n",
    "\n",
    "def sd_ratio(obs, mod):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation ratio of the model predictions and observations\n",
    "    \n",
    "    Args:\n",
    "        obs: numpy array of observed values\n",
    "        mod: numpy array of modeled values\n",
    "    Returns:\n",
    "        Standard deviation ratio   \n",
    "    \"\"\"\n",
    "    return np.std(mod) / np.std(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6109c-6acd-4961-a854-5319ca1342cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e52ce-c248-4c18-91bf-7d09e6fc9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denali setup\n",
    "#cluster = SLURMCluster() #TOH: my config defaults to Denali, but this won't work for other users\n",
    "\n",
    "cluster = LocalCluster(threads_per_worker=1)\n",
    "# Tallgrass setup\n",
    "#cluster = SLURMCluster(queue='cpu', cores=1, interface='ib0',\n",
    "#                       job_extra=['--nodes=1', '--ntasks-per-node=1', '--cpus-per-task=1'],\n",
    "#                       scheduler_options={'dashboard_address':36999},\n",
    "                       #cores=1, extra=['--resources processes=1']\n",
    "#                       memory='6GB')\n",
    "\n",
    "## PC setup\n",
    "#import os\n",
    "#n_cores = os.cpu_count() # set to match your machine\n",
    "\n",
    "client = Client(cluster)\n",
    "#client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cde09e-f489-48ac-9503-3797c44e19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.adapt(maximum_jobs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d914d65-d68f-4d4e-8269-7de128a24891",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed98767-f4b4-462b-8e12-217c244153b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c226be7-7ab0-4906-9bbf-fd9a6a0a34cc",
   "metadata": {},
   "source": [
    "# Intake catalog\n",
    "We use an Intake catalog to help manage the various datasets that might be used in an evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5cb00-f36a-4446-bd4c-3d49473cc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/nhm-usgs/data-pipeline-helpers/main/hytest/hytest_intake_catalog.yml'\n",
    "cat = intake.open_catalog(url)\n",
    "list(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9cc49d-f823-47dd-9422-4e598e37cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in intake\n",
    "obs_ds = cat['nwis-streamflow-usgs-gages-onprem'].to_dask()\n",
    "model_ds = cat['nwm21-streamflow-usgs-gages-onprem'].to_dask()\n",
    "\n",
    "\n",
    "obs = obs_ds['streamflow']\n",
    "mod = model_ds['streamflow'].astype('float32')\n",
    "\n",
    "obs.name = 'observed'\n",
    "mod.name = 'predicted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09932316-3a68-41fe-9e4b-20290aeee981",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d55d8-06f5-478d-abc8-7c9ee5ec28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.scatter(obs)\n",
    "client.scatter(mod)\n",
    "#client.scatter(ds_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f296eb-ab8f-4b07-a906-a1781a0c48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# selecting a single gage is fast\n",
    "gage_id = 'USGS-01030350'\n",
    "x = obs.sel(gage_id=gage_id).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a39bd-c0fe-417a-be73-10299e7bac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(gage_id):\n",
    "    # select the data for the given gage_id\n",
    "    # TODO the selection may be distributed, but can we force it onto a single node? Maybe by allocating 2 cores?\n",
    "    obs1 = obs.sel(gage_id=gage_id).to_series()\n",
    "    mod1 = mod.sel(gage_id=gage_id).to_series().resample('1D', offset='5h').mean() # Resampling could be done in preanalysis\n",
    "    # make sure the indices match\n",
    "    obs1.index = obs1.index.to_period('D')\n",
    "    mod1.index = mod1.index.to_period('D')\n",
    "\n",
    "\n",
    "    # merge obs and predictions and drop nans.\n",
    "    df = pd.merge(obs1, mod1, left_index=True, right_index=True).dropna(how='any')\n",
    "    obs1 = df['observed']\n",
    "    mod1 = df['predicted']\n",
    "    \n",
    "    # compute log flow for use in log NSE\n",
    "    threshold = 0.01\n",
    "    log_obs = np.log(obs1.where(obs1 > threshold, threshold))\n",
    "    log_model = np.log(mod1.where(mod1 > threshold, threshold))\n",
    "    \n",
    "    scores = pd.Series(dtype='float')\n",
    "    scores['nse'] = nse(obs1, mod1)\n",
    "    scores['log_nse'] = nse(log_obs, log_model)\n",
    "    scores['kge'] = kge(obs1, mod1)\n",
    "    \n",
    "    scores['pbias'] = pbias(obs1, mod1)\n",
    "    scores['pearson_r'] = pearson_r(obs1, mod1)\n",
    "    scores['spearman_r'] = spearman_r(obs1, mod1)\n",
    "    scores['sd_ratio'] = sd_ratio(obs1, mod1)\n",
    "    \n",
    "    # compute high flow and low flow bias\n",
    "    high_percentile = 98\n",
    "    low_percentile = 30\n",
    "    \n",
    "    scores['pbias_q' + str(high_percentile)] = pbias_percentile(obs1, mod1, high_percentile, np.greater)\n",
    "    scores['pbias_q' + str(low_percentile)] = pbias_percentile(obs1, mod1, high_percentile, np.less_equal)\n",
    "    scores.name = gage_id\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc67d14-ada2-444a-a6e7-09d973a1656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run for a single site using 1 core\n",
    "gage_id = 'USGS-01030350'\n",
    "compute_metrics(gage_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e57af6-375d-4650-85d9-a6aef964881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gages = list(obs.gage_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c62ec-9b01-4dbc-8ecd-64ad6b945aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57d2ce-9f37-46cd-a279-ccb67c0c879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143c588-af0d-4a5a-be37-d641fad49ced",
   "metadata": {},
   "source": [
    "#### Try Dask Delayed, computing a list of dask delayed objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad1436-1036-44a7-b2dd-a22db1803f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = dask.compute(*[dask.delayed(compute_metrics)(str(gage)) for gage in gages[:20]], retries=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f4cab0-ff96-4ca6-bfe7-687cd82f9943",
   "metadata": {},
   "source": [
    "#### Try Dask Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0021d5d-afbc-4341-af10-0dd93f9afac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "\n",
    "b = db.from_sequence(gages[:20], npartitions=10)\n",
    "b = b.map(compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd7a3d-fb01-49b5-a794-2a2480549eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = b.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43087ac2-278c-4c14-8ba5-811b941f0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(results, axis=1)\n",
    "df1 = df.T.reset_index()\n",
    "ds_results = xr.Dataset.from_dataframe(df1)\n",
    "ds_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab60ad-0818-4e0e-b1ed-0bcaffb17fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_results.sel(index='USGS-01030350')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc37280-813c-41a0-bdfb-7cf157083fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_results.to_netcdf('results.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fee5dd-24f6-4387-9977-c07a72831e8b",
   "metadata": {},
   "source": [
    "#### Open CSV file with obs info from Sydney Foks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e3707-368e-4c53-9c2a-2f04de8df5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5f24c-2138-42b7-885a-90ba38199216",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02ed2dc-7647-4678-85c0-3babca9ad70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 's3://esip-qhub-public/usgs/hytest/streamflow_benchmark_sites_v09.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da21243-ebef-4007-9e8a-3c2554b9849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fs.open(url), dtype={'site_no':str, 'huc_cd':str, 'reachcode':str, 'comid':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5950e61-a121-4daf-9705-64c2a1b088ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_ids = [ f'USGS-{site}'  for site in list(df['site_no'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e2193-16cb-4ae4-8188-a1e88376ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(site_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db702453-03e7-468a-b2d2-cddd0fa29f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dask.compute(*[dask.delayed(compute_metrics)(site) for site in site_ids[:20]], retries=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c036e49b-0f96-45ce-9481-ead23e58bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
