{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dfe0df-9f1a-4e5d-99d3-81f01a76d3c8",
   "metadata": {},
   "source": [
    "# HRRR Forecast Collection Best Time Series \n",
    "This notebook demonstrates how to access a collection of GRIB2 files as a single cloud-friendly dataset in xarray. \n",
    "\n",
    "We first use [kerchunk](https://github.com/fsspec/kerchunk) to create the JSON file that is then read by the zarr libaray using a referenceFileSystem created by fsspec.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602d057-f9c0-41b9-9009-9954dd99ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")  # filter some warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4c885-3e20-473b-aca5-63e611c181f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import dask\n",
    "import panel as pn\n",
    "import json\n",
    "import fsspec\n",
    "from kerchunk.grib2 import scan_grib\n",
    "from kerchunk.combine import MultiZarrToZarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81004cb7-ec55-4ea3-af2e-3ded369a71d9",
   "metadata": {},
   "source": [
    "#### Create a best time series dataset\n",
    "There is a new HRRR forecast every hour, so use forecast hour 1 from \n",
    "past forecasts and then append the latest forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b91313-d17d-479c-ba9f-5c0d462fc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=True, skip_instance_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ac735-d1b8-4389-9837-596e8cd18489",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.datetime.utcnow().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609e189-6a78-4148-94b6-96dffaef6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_file = fs.glob(f's3://noaa-hrrr-bdp-pds/hrrr.{today}/conus/*wrfsfcf01.grib2')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633bece-9da7-4cd3-90b8-a78ca333024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdff63-a4bb-4079-ac8b-0e236c7e517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = dt.datetime.strptime(last_file,\n",
    "        'noaa-hrrr-bdp-pds/hrrr.%Y%m%d/conus/hrrr.t%Hz.wrfsfcf01.grib2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c97a7-68de-44fd-bf75-1e3853bc61e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = end_time - dt.timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4b8ac-8004-4b19-884f-765411d48513",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5877b3d-0937-4450-8ce9-34e0a4a7c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_pattern_for_latest_forecast = end_time.strftime('s3://noaa-hrrr-bdp-pds/hrrr.%Y%m%d/conus/hrrr.t%Hz.wrfsfcf*.grib2')\n",
    "print(glob_pattern_for_latest_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127de370-74df-4c6a-99a1-7c70ef17a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start=start_time, end=end_time, freq='1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2cd64-4446-48b6-a86a-01e84780905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c9bbc-5039-42b9-bd88-42f219dbdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [date.strftime('s3://noaa-hrrr-bdp-pds/hrrr.%Y%m%d/conus/hrrr.t%Hz.wrfsfcf01.grib2') for date in dates]\n",
    "\n",
    "latest_files = fs.glob(glob_pattern_for_latest_forecast)\n",
    "latest_files = [f's3://{file}' for file in latest_files]\n",
    "print(latest_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be301d2-93d7-4083-aa9d-b16283528cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4178b-23ac-432c-9c78-09e0609056de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.extend(latest_files[2:])\n",
    "print(files[0])\n",
    "print(files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9b301-150a-4acb-8ace-aca018862258",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4889f-9979-4016-b492-ac54b3b1289d",
   "metadata": {},
   "source": [
    "#### Create Dask gateway cluster with credentials to write to specified S3 bucket\n",
    "Unless you are using the ESIP Qhub, you will need to modify the following cell to create a Dask cluster and supply your Dask workers with the necessary credentials to write to the S3 bucket.  Or modify to use a local Dask cluster and write JSON to local disk.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d7312e-ccbf-4962-8320-12a31fbabe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['HOME'],'shared','users','lib'))\n",
    "import ebdpy as ebd\n",
    "\n",
    "profile = 'esip-qhub'\n",
    "region = 'us-west-2'\n",
    "endpoint = f's3.{region}.amazonaws.com'\n",
    "\n",
    "ebd.set_credentials(profile=profile, region=region, endpoint=endpoint)\n",
    "worker_max = 30\n",
    "client,cluster = ebd.start_dask_cluster(profile=profile,worker_max=worker_max, \n",
    "                                      region=region, use_existing_cluster=True,\n",
    "                                      adaptive_scaling=False, wait_for_cluster=True, \n",
    "                                      environment='pangeo', worker_profile='Medium Worker', \n",
    "                                      propagate_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3cfec3-454d-49ed-a503-a09d0dd23e87",
   "metadata": {},
   "source": [
    "#### Create individual ReferenceFileSystem jsons\n",
    "The `afilter` below controls which grib variables we want [cfgrib](https://github.com/ecmwf/cfgrib#filter-heterogeneous-grib-files) to capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e0a8f-dd42-4864-a50d-dd3ed765cf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "afilter={'typeOfLevel': 'heightAboveGround', 'level': 2}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4cdab-0731-4e3e-823b-c64c24ab7760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "so = {\"anon\": True, \"default_cache_type\": \"readahead\"}\n",
    "common = ['time', 'step', 'latitude', 'longitude', 'valid_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b2d05-a816-4f9f-acff-a6a7ff821e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_json(u):\n",
    "    date = u.split('/')[3].split('.')[1]\n",
    "    name = u.split('/')[5].split('.')[1:3]\n",
    "    outfname = f'{json_dir}{date}.{name[0]}.{name[1]}.json'\n",
    "    out = scan_grib(u, common, so, inline_threashold=100, filter=afilter)        \n",
    "    with fs2.open(outfname, \"w\") as f:\n",
    "        f.write(json.dumps(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71eaddc-3ba2-4c25-b901-c50a7f97323d",
   "metadata": {},
   "source": [
    "#### Bucket to store individual JSONs (need permission, so anon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3d4f8d-ffad-49f8-9662-3c5e45c99d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = 's3://esip-qhub/noaa/hrrr/jsons/'\n",
    "fs2 = fsspec.filesystem('s3', anon=False, skip_instance_cache=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41dcff-5afd-46ae-815c-c5778494b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fs2.rm(json_dir, recursive=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e82ad-39fa-424b-9ef6-c3733f4baeea",
   "metadata": {},
   "source": [
    "#### Compute the individual JSONs in parallel by computing a list of Dask delayed objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9dd6a5-18c9-4906-b39e-a87e7f937d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = dask.compute(*[dask.delayed(gen_json)(u) for u in files], retries=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de93a03-e72d-45f9-b369-86ddc0e9b272",
   "metadata": {},
   "source": [
    "#### Use `MultiZarrToZarr()` to combine into single reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f03e4c-4542-4efd-8e50-92df9371fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist2 = fs2.ls(json_dir)\n",
    "furls = sorted(['s3://'+f for f in flist2])\n",
    "print(furls[0])\n",
    "print(furls[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347052f6-2a8c-40f1-a202-585bb83a0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "furls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d9483-6867-4d6b-be23-b39c97ed529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mzz = MultiZarrToZarr(furls, \n",
    "            storage_options={'anon':False},\n",
    "            remote_protocol='s3', \n",
    "            remote_options={'anon': True},\n",
    "            xarray_concat_args={'dim': 'valid_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1b1f4-9242-474e-a2d6-adddfa527ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%%prun -D multizarr_profile \n",
    "mzz.translate('hrrr_best.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc4c1a-e31d-4cbd-8cd1-8b2d2a5042f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = 's3://esip-qhub-public/noaa/hrrr/hrrr_best.json'\n",
    "fs2.put_file(lpath='hrrr_best.json', rpath=rpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe306843-f0bc-4dae-9e6c-74a6c1a789e5",
   "metadata": {},
   "source": [
    "## Examine resulting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1055e-bb20-49e1-8008-157e62827fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpath = 's3://esip-qhub-public/noaa/hrrr/hrrr_best.json'\n",
    "s_opts = {'requester_pays':True, 'skip_instance_cache':True}\n",
    "r_opts = {'anon':True}\n",
    "fs = fsspec.filesystem(\"reference\", fo=rpath, ref_storage_args=s_opts,\n",
    "                       remote_protocol='s3', remote_options=r_opts)\n",
    "m = fs.get_mapper(\"\")\n",
    "\n",
    "ds2 = xr.open_dataset(m, engine=\"zarr\", backend_kwargs=dict(consolidated=False), \n",
    "                      chunks={'valid_time':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677f2dc-f4f5-466c-9ac3-e983fa32baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf91e48-4b4d-49ab-ae8a-e52c7458232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var='t2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7ddb3-621d-48d7-93d9-a56e6f2ece60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Size:{ds2[var].nbytes/1e9} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921439f7-1963-4ce1-a66d-06fa729937a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199fcb9-3b85-47ea-80de-e80232c1e2ec",
   "metadata": {},
   "source": [
    "Hvplot wants lon [-180,180], not [0,360]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad699973-8780-49ac-a7c0-7ce3f74a7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds2.assign_coords(longitude=(((ds2.longitude + 180) % 360) - 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408c1b6-06a9-43d3-b69a-1b73dc0d9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.datetime.utcnow().strftime('%Y-%m-%d %H:00:00')\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95869e81-657b-4fb1-9553-b9197c92bbd1",
   "metadata": {},
   "source": [
    "With 30 worker cluster, takes 50 seconds to display, and 15 seconds to change the time step\n",
    "after closing the dask client, it takes 30 seconds to display, 8 seconds to display a time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c7153-efb7-4aa0-acac-ec308a691f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2[var].sel(valid_time=now).hvplot.quadmesh(x='longitude', y='latitude', geo=True,\n",
    "                                                rasterize=True, cmap='turbo', title=now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d3a95b-113b-44cc-883f-96cce3d75940",
   "metadata": {},
   "source": [
    "hvplot has a slider for time steps, but we want a dropdown list, so we use Panel.  Let's add a tile layer from Open Street Map also. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605c99a-e5f1-4ced-b1fa-d10cd29a563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_dims = list(ds2[var].dims[:-2])\n",
    "mesh = ds2[var].hvplot.quadmesh(x='longitude', y='latitude', rasterize=True, geo=True, tiles='OSM', cmap='turbo')\n",
    "pn.panel(mesh, widgets={k: pn.widgets.Select for k in extra_dims})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa77bb5-1c95-46c6-a24d-79571b4165da",
   "metadata": {},
   "source": [
    "#### Extract a time series at a point\n",
    "We are reading GRIB2 files, which compress the entire spatial domain as a single chunk.  Therefore reading all the time values at a single point actually needs to load and uncompress *all* the data for that variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474541e-383a-4839-a4f2-da4e459a7619",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds2[var][:,500,500].hvplot(x='valid_time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f2f21-c67a-4c7a-9d3e-d7060af3b4d2",
   "metadata": {},
   "source": [
    "#### Compute the time-mean temperature over the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bda28a-73d2-47ef-b505-8faa008924f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds2[var].mean(dim='valid_time').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668067cb-14ce-4357-9d24-fd24ac9cb9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "da.hvplot.quadmesh(x='longitude', y='latitude', rasterize=True, geo=True, tiles='OSM', cmap='turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e30a8a6-ad1b-41e3-b77d-c9cf640f2cab",
   "metadata": {},
   "source": [
    "#### Close the client and shutdown the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d8cec-b866-4a88-a88a-acd95f50b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close(); cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bb83a-6e55-4d62-a0c8-a9b4eb2b79fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
