{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert HRRR to Zarr\n",
    "#### Step 1/3: Download GRIB2 files and convert to NetCDF\n",
    "The goal of this workflow is to create a single \"best time series\" cloud-optimized HRRR dataset in Zarr.  There are 36 hour forecasts available at 0, 6, 12 and 18 hours, and 18 hour forecasts at every hour in between.  To create our \"best time series\" we use the tau=1, 1 hour forecast data, to allow a bit of dynamic adjustment away from the analysis time.   \n",
    "\n",
    "The workflow is: \n",
    "1. Download the HRRR GRIB2 file corresponding to the tau=1 forecast for each hour\n",
    "2. Convert to NetCDF using \"wgrib2\"\n",
    "3. Fill in gaps with tau>1 from previous forecast cycles (e.g. to (fill a gap at tau=1 in the forecast run at 06:00 with tau=7 in the forecast run at 00:00 )\n",
    "3. Rechunk the data using rechunker (producing Zarr format)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fsspec\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import subprocess\n",
    "import os\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "import os\n",
    "cluster = SLURMCluster(processes=1, cores=36, memory='3GB',\n",
    "                    walltime='23:00:00', queue='compute')\n",
    "\n",
    "print(cluster.job_script())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client=Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'noaa-hrrr-bdp-pds'  # archive'\n",
    "ldir = '/vortexfs1/usgs/rsignell/HRRR/nc2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = fs.glob(f'{bucket}/hrrr.20190101/conus/*sfcf01*.grib2')\n",
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_file = fsspec.open_local(f'simplecache::s3://{flist[0]}', \n",
    "#                              s3=dict(anon=True), simplecache={'cache_storage': '/tmp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = xr.open_dataset(tmp_file, engine='cfgrib', \n",
    "#                       backend_kwargs=dict(filter_by_keys={'typeOfLevel': 'heightAboveGround', 'level': 2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='2019-01-01 00:00',end='2019-12-31 23:00', freq='1h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'noaa-hrrr-bdp-pds/hrrr.20190101/conus/hrrr.t00z.wrfnatf01.grib2'\n",
    "'noaa-hrrr-bdp-pds/hrrr.20190101/conus/hrrr.t01z.wrfnatf01.grib2',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmatch = \"(:TMP:2 m above ground:|:RH:2 m above ground:|:UGRD:10 m above ground:|:VGRD:10 m above ground:|:PRATE:surface:|:DSWRF:surface:|:DLWRF:surface:|:USWRF:surface:)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmissing=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def hrrr_grib2nc(date):\n",
    "    yyyymmdd = date.strftime('%Y%m%d')\n",
    "    hh = date.strftime('%H')\n",
    "    cfile = f's3://noaa-hrrr-bdp-pds/hrrr.{yyyymmdd}/conus/hrrr.t{hh}z.wrfsfcf01.grib2'\n",
    "    fname = f'{ldir}/hrrr.{yyyymmdd}{hh}.wrfsfcf01.grib2' \n",
    "    if not os.path.exists(fname):\n",
    "        try:\n",
    "            fs.download(cfile,fname)\n",
    "            output = fname.replace(\".grib2\", \".nc2\")\n",
    "            call = [\"wgrib2\", fname, \"-match\", vmatch, \"-netcdf\", output]\n",
    "            verbose=False\n",
    "            ret = False\n",
    "            # Not very robust check but will allow you to re-run everything in case a single file failed.\n",
    "            if not os.path.exists(output):\n",
    "                ret = subprocess.run(call, capture_output=True)\n",
    "            if verbose:\n",
    "                print(ret.stdout.decode())\n",
    "            if ret and ret.returncode == 0:\n",
    "                print(f\"Converted {fname} to {output}.\")\n",
    "        except:\n",
    "            print(f'{cfile} not found')\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [hrrr_grib2nc(date) for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dask.compute(tasks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close(); cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
