{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore USGS Terrain COGs\n",
    "This 1 arc second (~30m) resolution terrain data as 32-bit cloud-optimized geotiff in a public AWS bucket.  Each file is a 1x1 degree square. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "import fsspec\n",
    "import os\n",
    "import rioxarray \n",
    "from rioxarray.merge import merge_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GDAL settings from [COG Best Practices](https://github.com/pangeo-data/cog-best-practices/blob/main/0-single-cog.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN']='EMPTY_DIR' #This is KEY! otherwise we send a bunch of HTTP GET requests to test for common sidecar metadata\n",
    "os.environ['AWS_NO_SIGN_REQUEST']='YES' #Since this is a public bucket, we don't need authentication\n",
    "os.environ['GDAL_MAX_RAW_BLOCK_CACHE_SIZE']='200000000'  #200MB: Want this to be greater than size of uncompressed raster to overcome a 10 MB limit in the GeoTIFF driver for range request merging.\n",
    "os.environ['GDAL_SWATH_SIZE']='200000000'  #also increase this if increasing MAX_RAW_BLOCK_CACHE_SIZE\n",
    "os.environ['VSI_CURL_CACHE_SIZE']='200000000' #also increase this if increasing MAX_RAW_BLOCK_CACHE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore a sample terrain square (the 1x1 degree square that contains most of Cape Cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_url = 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF/n42w071/USGS_1_n42w071.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(da):\n",
    "    x = da['x'].values; x0 = x.min().round(); x1 = x.max().round()\n",
    "    y = da['y'].values; y0 = y.min().round(); y1 = y.max().round()\n",
    "    return da.sel(x=slice(x0,x1), y=slice(y1,y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to merge images along latitude, then merge those merged images along longitude. This should allow the coordinates to align along the merged dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF'\n",
    "urls = []\n",
    "da_lon = []\n",
    "for lon in [-80, -79]:\n",
    "    da_lat = []\n",
    "    for lat in [41, 42]:\n",
    "        url = f'{prefix}/n{lat:02d}w{-lon:03d}/USGS_1_n{lat:02d}w{-lon:03d}.tif'\n",
    "        try:\n",
    "            if res==30:\n",
    "                da = rxr.open_rasterio(url, masked=True, chunks=True)\n",
    "            else:\n",
    "                level = int(res/30) - 2   # 60m = 0, 120m = 1, etc\n",
    "                da = rioxarray.open_rasterio(url, masked=True, chunks=True, \n",
    "                                             overview_level=level)\n",
    "            da = da.squeeze('band').sel(y=slice(None,None,-1))   # flip the y dimension so that it is ascending\n",
    "            da_lat.append(clip(da))                              # clip to degree square and append\n",
    "            urls.append(url)\n",
    "        except:\n",
    "            pass\n",
    "    da_col = xr.concat(da_lat, dim='y')\n",
    "    da_lon.append(da_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'https://prd-tnm.s3.amazonaws.com/StagedProducts/Elevation/1/TIFF'\n",
    "urls = []\n",
    "darrays = []\n",
    "for lon in [-80, -79]:\n",
    "    da_lat = []\n",
    "    for lat in [41, 42]:\n",
    "        url = f'{prefix}/n{lat:02d}w{-lon:03d}/USGS_1_n{lat:02d}w{-lon:03d}.tif'\n",
    "        try:\n",
    "            if res==30:\n",
    "                da = rioxarray.open_rasterio(url, masked=True, chunks=True)\n",
    "            else:\n",
    "                level = int(res/30) - 2   # 60m = 0, 120m = 1, etc\n",
    "                da = rioxarray.open_rasterio(url, masked=True, chunks=True, \n",
    "                                             overview_level=level)\n",
    "            da = da.squeeze('band', drop=True) \n",
    "            darrays.append(clip(da))                              # clip to degree square and append\n",
    "            urls.append(url)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = merge_arrays(darrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darrays[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darrays[0].max().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_whole = xr.concat(da_lon, dim='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_whole.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize with hvplot from the holoviz.org tool suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = da_lon[0].hvplot.image(x='x', y='y', geo=True, rasterize=True, \n",
    "                frame_width=500, cmap='rainbow', tiles='ESRI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = da_lon[1].hvplot.image(x='x', y='y', geo=True, rasterize=True, \n",
    "                frame_width=500, cmap='rainbow', tiles='ESRI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the full list of available degree squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = fs.glob('prd-tnm/StagedProducts/Elevation/1/TIFF/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist[-5:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
