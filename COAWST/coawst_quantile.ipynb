{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring COAWST coupled circulation/wave forecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import numpy as np\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray uses Dask behind the scenes, so spin up a Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.environ['HOME'],'shared','users','lib'))\n",
    "import ebdpy as ebd\n",
    "ebd.set_credentials(profile='esip-qhub')\n",
    "\n",
    "aws_profile = 'esip-qhub'\n",
    "aws_region = 'us-west-2'\n",
    "endpoint = f's3.{aws_region}.amazonaws.com'\n",
    "ebd.set_credentials(profile=aws_profile, region=aws_region, endpoint=endpoint)\n",
    "worker_max = 90\n",
    "client,cluster = ebd.start_dask_cluster(profile=aws_profile, worker_max=worker_max, \n",
    "                                      region=aws_region, use_existing_cluster=True,\n",
    "                                      adaptive_scaling=False, wait_for_cluster=True, \n",
    "                                      environment='pangeo', worker_profile='Pangeo Worker', \n",
    "                                      propagate_env=True)     #client.close(); cluster.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close(); cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Read rechunked Zarr data from AWS Cloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(fs.get_mapper('s3://esip-qhub/usgs/COAWST/surface_vars/'), \n",
    "                   consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Hwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ds['Hwave'].chunk({'eta_rho':100, 'xi_rho':100, 'ocean_time':-1}).quantile(q=np.linspace(0, 1, num=21), dim='ocean_time')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "b = dask.compute(a, retries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.close; cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.sel(quantile=0.45)\n",
    "c.where(c>0).hvplot.quadmesh(x='lon_rho', y='lat_rho', geo=True, frame_height=400,\n",
    "                  rasterize=True, cmap='turbo', tiles='OSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
