{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing data on cloud object storage (AWS S3)\n",
    "Reading from and writing to S3 object storage is a bit different than regular filesystems.   Here we access public read buckets, requester pays buckets and write to a private bucket for Pangeo users.  We will make much use of `fsspec`, which offers filesystem interfaces to S3 (also HTTPS, FTP and many others) in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore items on a public-read S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=True)\n",
    "fs.ls('anaconda-public-datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use glob to explore items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.glob('anaconda-public-datasets/*/*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read a CSV file from a public read bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = fsspec.open(\"s3://anaconda-public-datasets/iris/iris.csv\", \n",
    "                     mode='rt', anon=True)\n",
    "with infile as f:\n",
    "    df = pd.read_csv(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing data to S3 buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write data, you must first set up your AWS credentials.  Open a terminal and type `aws configure --profile esip-qhub` to run a script which will ask for your AWS credentials (the `aws_access_key_id` and `aws_secret_access_key` provided to you. These will be stored in `/home/jovyan/.aws/credentials` with the profile name `esip-qhub`.  Make sure you don't commit or share that file anywhere!).  \n",
    "\n",
    "Once the credentials are in place, you should be able to write to buckets where your credentials have permission.   On the ESIP qhub, this is the `s3://esip-qhub` bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = fsspec.open(f\"s3://esip-qhub/usgs/testing/iris.csv\", \n",
    "                      mode='wt', profile='esip-qhub')\n",
    "\n",
    "with outfile as f:\n",
    "    df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List items in a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=False, profile='esip-qhub')\n",
    "fs.ls(f'esip-qhub/usgs/testing/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The rest of the examples will use xarray, which follows the NetCDF data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open a NetCDF file from an HTTP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = fsspec.open('simplecache::https://geoport.usgs.esipfed.org/erddap/files/8544pcs-cal_z3/8544pcs-cal_z3.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(infile.open(), engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = fsspec.open('simplecache::s3://esip-qhub/usgs/testing/8544pcs-cal_z3.nc', \n",
    "                      mode='wb', s3=dict(profile='esip-qhub'))\n",
    "with outfile as f:\n",
    "    ds.to_netcdf(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read NetCDF data from a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = fsspec.open(f's3://esip-qhub/usgs/testing/8544pcs-cal_z3.nc')\n",
    "ds = xr.open_dataset(ncfile.open())\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read NetCDF data from THREDDS OPeNDAP Service  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('http://geoport.usgs.esipfed.org/thredds/dodsC/silt/usgs/Projects/stellwagen/CF-1.6/BUZZ_BAY/2651-A.cdf')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualation interlude: plot a time range of data with hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "\n",
    "ds['T_20'].sel(time=slice('1982-10-01','1982-10-31')).hvplot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read NetCDF data from ERDDAP's Tabledap Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('http://erddap.sensors.ioos.us/erddap/tabledap/gov_usgs_cmgp_buzz_bay_265')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read NetCDF data from ERDDAP's griddap Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://geoport.usgs.esipfed.org/erddap/griddap/adcp_grid_5d6e_e2f9_148d'\n",
    "\n",
    "ds = xr.open_dataset(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['CS_300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['CS_300'].sel(time=slice('2009-10-01T12:00:00','2009-10-14T12:00:00')).isel(altitude=[0,1,-1]).hvplot(x='time', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List items on a Requester Pays bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=False, requester_pays=True)\n",
    "fs.ls('esip-qhub/noaa/nwm/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Zarr dataset from a Requester Pays S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Zarr datasets, each chunk is a separate object, so instead of opening a file, we use a mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(fsspec.get_mapper('s3://esip-qhub/noaa/nwm', \n",
    "                            anon=False, requester_pays=True), consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write Zarr dataset to S3 using LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3store = fsspec.get_mapper(f's3://esip-qhub/usgs/testing/zarr_test', \n",
    "                                    anon=False, profile='esip-qhub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write first time step of Zarr dataset to Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds.isel(time=0).load().to_zarr(store=s3store, mode='w', consolidated=True)   #fails without .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()   # close the LocalCluster client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Zarr Dataset to S3 using a remote cluster\n",
    "Here we spin up a Qhub Dask Gateway cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client\n",
    "gateway = Gateway()\n",
    "# see Gateway options to use in new_cluster by doing: gateway.cluster_options()\n",
    "cluster = gateway.new_cluster(environment='pangeo', profile='Pangeo Worker')  \n",
    "cluster.scale(4)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds.isel(time=0).load().to_zarr(store=s3store, mode='w', consolidated=True) #fails without .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close(); cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
