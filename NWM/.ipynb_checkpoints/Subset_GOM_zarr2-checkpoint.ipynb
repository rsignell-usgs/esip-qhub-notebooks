{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import fsspec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a Dask cluster\n",
    "This is not required, but speeds up computations. Once can start a local cluster by just doing:\n",
    "```\n",
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "```\n",
    "but there are [many other ways to set up Dask clusters](https://docs.dask.org/en/latest/setup.html) that can scale larger than this. \n",
    "\n",
    "Since we used [Qhub](https://www.quansight.com/post/announcing-qhub) to install JupyterHub with a Dask Gateway running on Kubernetes, we can start a Dask cluster (with a specified environment and worker profile), scale it, and connect to it thusly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.environ['HOME'],'shared','users','lib'))\n",
    "import ebdpy as ebd\n",
    "\n",
    "ebd.set_credentials(profile='esip-qhub')\n",
    "\n",
    "profile = 'esip-qhub'\n",
    "region = 'us-west-2'\n",
    "endpoint = f's3.{region}.amazonaws.com'\n",
    "ebd.set_credentials(profile=profile, region=region, endpoint=endpoint)\n",
    "worker_max = 10\n",
    "client,cluster = ebd.start_dask_cluster(profile=profile,worker_max=worker_max, \n",
    "                                      region=region, use_existing_cluster=True,\n",
    "                                      adaptive_scaling=False, wait_for_cluster=False, \n",
    "                                      environment='pangeo', worker_profile='Pangeo Worker', propagate_env=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Zarr datasets in Xarray using a mapper from fsspec.  We use `anon=True` for free-access public buckets like the AWS Open Data Program, and `requester_pays=True` for requester-pays public buckets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 's3://noaa-nwm-retro-v2-zarr-pds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't specify a profile here because we've passed the AWS credentials via environment variables to the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('s3', anon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds = xr.open_zarr(fs.get_mapper(url), consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Variable size: {ds[var].nbytes/1e12:.1f} TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (ds.latitude > 41.0) & (ds.latitude < 51.0) & (ds.longitude > -75.0) & (ds.longitude < -62.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = ds[['streamflow']].isel(feature_id=idx).isel(time=slice(0,672))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_out = ds[['streamflow']].isel(feature_id=idx).sel(time=slice('2000-01-01',None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gchunks(ds_chunk, chunks):\n",
    "    group_chunks = {}\n",
    "\n",
    "    for var in ds_chunk.variables:\n",
    "        # pick appropriate chunks from above, and default to full length chunks for dimensions that are not in `chunks` above.\n",
    "        group_chunks[var] = []\n",
    "        for di in ds_chunk[var].dims:\n",
    "            if di in chunks.keys():\n",
    "                if chunks[di] > len(ds_chunk[di]):\n",
    "                    group_chunks[var].append(len(ds_chunk[di]))\n",
    "                else:\n",
    "                    group_chunks[var].append(chunks[di])\n",
    "\n",
    "            else:\n",
    "                group_chunks[var].append(len(ds_chunk[di]))\n",
    "\n",
    "        ds_chunk[var] = ds_chunk[var].chunk(tuple(group_chunks[var]))\n",
    "        group_chunks[var] = {'chunks':tuple(group_chunks[var])}\n",
    "    return group_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = gchunks(ds_out, {'time':672, 'feature_id':10000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_out.to_zarr(fs.get_mapper('esip-qhub/usgs/rsignell/testing/zarr/gulf_of_maine'), \n",
    "                mode='w', encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
